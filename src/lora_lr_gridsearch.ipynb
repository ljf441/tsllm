{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljf1/dis/lora/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from preprocessor import load_and_preprocess, decoding, process_data\n",
    "from qwen import load_qwen\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from preprocessor import get_dataset\n",
    "\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchtune\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for matplotlib plots\n",
    "SMALL_SIZE = 15+5\n",
    "MEDIUM_SIZE = 20+5\n",
    "BIGGER_SIZE = 25+5\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "test_size = 0.2\n",
    "max_steps = 200\n",
    "max_ctx_length = 512 #768#512\n",
    "weight_decay = 0.01\n",
    "points = 80\n",
    "\n",
    "# Define parameter grid\n",
    "lora_ranks = [2, 4, 8]\n",
    "learning_rates = [1e-5, 5e-5, 1e-4]\n",
    "\n",
    "rank = lora_ranks[2]\n",
    "lr = learning_rates[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, original_linear: nn.Linear, r: int, alpha: int = None):\n",
    "        super().__init__()\n",
    "        assert isinstance(original_linear, nn.Linear)\n",
    "        self.original_linear = original_linear\n",
    "        self.original_linear.weight.requires_grad = False\n",
    "        if self.original_linear.bias is not None:\n",
    "            self.original_linear.bias.requires_grad = False\n",
    "        in_dim = original_linear.in_features\n",
    "        out_dim = original_linear.out_features\n",
    "        self.r = r\n",
    "        self.alpha = alpha if alpha else r\n",
    "\n",
    "        device = original_linear.weight.device\n",
    "        self.A = nn.Parameter(torch.empty(r, in_dim, device=device))\n",
    "        self.B = nn.Parameter(torch.zeros(out_dim, r, device=device))\n",
    "        \n",
    "        # Initialise A with He initialization\n",
    "        nn.init.kaiming_normal_(self.A, nonlinearity=\"linear\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_out = self.original_linear(x)\n",
    "        lora_out = (x @ self.A.T) @ self.B.T\n",
    "        return base_out + lora_out * (self.alpha / self.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters\n",
    "lora_rank = rank\n",
    "lora_alpha = 2*lora_rank\n",
    "learning_rate = lr\n",
    "\n",
    "model, tokenizer = load_qwen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data into sequences of text\n",
    "train_texts, val_texts, test_texts = load_and_preprocess(\"lotka_volterra_data.h5\", test_size=test_size)\n",
    "\n",
    "# ^Each of these is a `list[str]` representing contiguous parts of the time series,\n",
    "#  in text form (using the LLMTIME scheme).\n",
    "\n",
    "# Modified tokenization with chunking\n",
    "def process_sequences(texts, tokenizer, max_length=512, stride=256):\n",
    "    all_input_ids = []\n",
    "    for text in texts:\n",
    "        # Apply Qwen's tokenization scheme to the text:\n",
    "        encoding = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False, padding_side='left')\n",
    "        seq_ids = encoding.input_ids[0]\n",
    "\n",
    "        # Create sliding windows to further divide the data into chunks:\n",
    "        for i in range(0, len(seq_ids), stride):\n",
    "            chunk = seq_ids[i : i + max_length]\n",
    "            if len(chunk) < max_length:\n",
    "                chunk = torch.cat(\n",
    "                    [\n",
    "                        torch.full((max_length - len(chunk),), tokenizer.pad_token_id),\n",
    "                        chunk,\n",
    "                    ]\n",
    "                )\n",
    "            all_input_ids.append(chunk)\n",
    "    return torch.stack(all_input_ids)\n",
    "\n",
    "\n",
    "def process_data(texts, tokenizer, points=80):\n",
    "    given_input_ids = []\n",
    "    for text in texts:\n",
    "        given_text = ';'.join([chunk for i, chunk in enumerate(text.split(';')) if i < points])\n",
    "        encoding_given = tokenizer(given_text, return_tensors=\"pt\", padding='max_length', padding_side='left', max_length=1200)\n",
    "        given_input_ids.append(encoding_given.input_ids[0])\n",
    "    return np.stack([text for text in texts]), torch.stack(given_input_ids)\n",
    "\n",
    "def running_mse(prediction, actual):\n",
    "    mse = []\n",
    "    for i in range(len(prediction)):\n",
    "        mse.append(mean_squared_error(prediction[:i+1], actual[:i+1]))\n",
    "    return mse\n",
    "\n",
    "def evaluate_model(model, val_loader, step, max_batches=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch,) in enumerate(tqdm(val_loader, desc=\"val set\")):\n",
    "            # Exit loop after processing max_batches\n",
    "            if max_batches is not None and batch_idx >= max_batches:\n",
    "                break\n",
    "            outputs = model(batch, labels=batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    \n",
    "    # Calculate metrics - divide by actual number of batches processed\n",
    "    num_batches = min(len(val_loader), max_batches) if max_batches is not None else len(val_loader)\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    print(f'Loss on validation subset ({num_batches}/{len(val_loader)} batches) at step {step}: {avg_loss:.4f}')\n",
    "    return avg_loss\n",
    "\n",
    "# Defines the maximum context length for the model\n",
    "train_input_ids = process_sequences(\n",
    "    train_texts, tokenizer, max_ctx_length, stride=max_ctx_length // 2\n",
    ")\n",
    "val_input_ids = process_sequences(\n",
    "    val_texts, tokenizer, max_ctx_length, stride=max_ctx_length\n",
    ")\n",
    "test_texts_all, test_input_ids_some = process_data(\n",
    "    test_texts, tokenizer, points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TensorDataset(train_input_ids)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_input_ids)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids_some)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training with lora_rank=8, learning_rate=0.0001\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val set: 100%|██████████| 75/75 [01:34<00:00,  1.26s/it]\n",
      "Steps 0:   0%|          | 1/1000 [01:40<27:59:03, 100.84s/it, loss=2.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation subset (75/75 batches) at step 0: 3.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val set: 100%|██████████| 75/75 [01:35<00:00,  1.28s/it]/it, loss=0.936]\n",
      "Steps 0:   5%|▌         | 51/1000 [07:10<8:51:54, 33.63s/it, loss=0.959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation subset (75/75 batches) at step 50: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val set: 100%|██████████| 75/75 [01:35<00:00,  1.28s/it]s/it, loss=0.808]\n",
      "Steps 0:  10%|█         | 101/1000 [12:38<8:18:40, 33.28s/it, loss=0.854]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation subset (75/75 batches) at step 100: 0.6952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val set: 100%|██████████| 75/75 [01:34<00:00,  1.26s/it]s/it, loss=0.81] \n",
      "Steps 0:  15%|█▌        | 151/1000 [18:04<7:45:42, 32.91s/it, loss=0.401]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation subset (75/75 batches) at step 150: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps 0:  20%|█▉        | 199/1000 [21:55<1:28:14,  6.61s/it, loss=0.723]\n",
      "val set: 100%|██████████| 75/75 [01:14<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation subset (75/75 batches) at step 200: 0.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results\n",
    "grid_results = {}\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training with lora_rank={lora_rank}, learning_rate={learning_rate}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Apply LoRA with current rank\n",
    "for layer in model.model.layers:\n",
    "    layer.self_attn.q_proj = LoRALinear(layer.self_attn.q_proj, r=lora_rank, alpha=lora_alpha)\n",
    "    layer.self_attn.v_proj = LoRALinear(layer.self_attn.v_proj, r=lora_rank, alpha=2*lora_alpha)\n",
    "\n",
    "# Create optimizer with current learning rate\n",
    "optimizer = torch.optim.Adam(\n",
    "    (p for p in model.parameters() if p.requires_grad), \n",
    "    lr=learning_rate, \n",
    "    # weight_decay=weight_decay,\n",
    ")\n",
    "\n",
    "# Prepare with accelerator\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_loader_local, val_loader_local, test_loader_local = accelerator.prepare(\n",
    "    model, optimizer, train_loader, val_loader, test_loader\n",
    ")\n",
    "\n",
    "# Train the model (shortened training for grid search)\n",
    "steps = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "early_stop_steps = min(max_steps, 500)  # Reduce training for grid search\n",
    "\n",
    "while steps < early_stop_steps:\n",
    "    progress_bar = tqdm(train_loader_local, desc=f\"Steps {steps}\")\n",
    "    for (batch,) in progress_bar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss\n",
    "        train_losses.append([loss.item(), steps])\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (steps % 50) == 0:\n",
    "            avg_loss = evaluate_model(model, val_loader_local, steps)\n",
    "            val_losses.append([avg_loss, steps])\n",
    "            model.train()\n",
    "            \n",
    "        steps += 1\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        if steps >= early_stop_steps:\n",
    "            break\n",
    "\n",
    "# Final evaluation\n",
    "final_val_loss = evaluate_model(model, val_loader_local, steps)\n",
    "\n",
    "# Store results\n",
    "grid_results[(lora_rank, learning_rate)] = {\n",
    "    \"final_val_loss\": final_val_loss,\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "}\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "del optimizer\n",
    "del train_loader_local\n",
    "del val_loader_local\n",
    "del test_loader_local\n",
    "del accelerator\n",
    "del train_losses\n",
    "del val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/grid_history_8_0.0001.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_results, f\"../results/grid_results_{rank}_{lr}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# # Print and save results\n",
    "# print(\"\\n\\nGrid Search Results:\")\n",
    "# print(\"=====================\")\n",
    "# for params, results in grid_results.items():\n",
    "#     print(f\"lora_rank={params[0]}, learning_rate={params[1]}: validation loss = {results['final_val_loss']:.6f}\")\n",
    "\n",
    "# print(f\"\\nBest parameters: lora_rank={best_params[0]}, learning_rate={best_params[1]}, validation loss = {best_val_loss:.6f}\")\n",
    "\n",
    "# # Save grid search results\n",
    "# joblib.dump(grid_results, f\"../results/grid_search_results.pkl\")\n",
    "\n",
    "# # Create visualization of grid search results\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# for params, results in grid_results.items():\n",
    "#     plt.plot(np.arange(len(results['train_losses'])), \n",
    "#              results['train_losses'], \n",
    "#              label=f\"rank={params[0]}, lr={params[1]}\", \n",
    "#              alpha=0.7)\n",
    "\n",
    "# plt.xlabel(\"Steps\")\n",
    "# plt.ylabel(\"Training Loss\")\n",
    "# plt.title(\"Training Loss by Hyperparameter Configuration\")\n",
    "# plt.legend()\n",
    "# plt.savefig(\"../plots/lora_lr_grid_search_training_losses.png\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot validation losses\n",
    "# val_loss_data = {params: results[\"final_val_loss\"] for params, results in grid_results.items()}\n",
    "# params_labels = [f\"rank={p[0]}, lr={p[1]}\" for p in val_loss_data.keys()]\n",
    "# val_losses = list(val_loss_data.values())\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.bar(params_labels, val_losses)\n",
    "# plt.xlabel(\"Hyperparameters\")\n",
    "# plt.ylabel(\"Final Validation Loss\")\n",
    "# plt.title(\"Validation Loss by Hyperparameter Configuration\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"../plots/lora_lr_grid_search_validation_losses.png\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
