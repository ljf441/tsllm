\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{h5py}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{torch}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn.model\PYGZus{}selection} \PYG{k+kn}{import} \PYG{n}{train\PYGZus{}test\PYGZus{}split}
\PYG{k+kn}{import} \PYG{n+nn}{re}
\PYG{k}{def} \PYG{n+nf}{get\PYGZus{}dataset}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{n}{system\PYGZus{}id}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{points}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Load the Lotka\PYGZhy{}Volterra dataset from an HDF5 file and extract the prey and predator data.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        file\PYGZus{}path (str): Path to the HDF5 file.}
\PYG{l+s+sd}{        system\PYGZus{}id (int): The ID of the system to load.}
\PYG{l+s+sd}{        points (int): The number of points to load.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        prey (np.ndarray): The prey values.}
\PYG{l+s+sd}{        predator (np.ndarray): The predator values.}
\PYG{l+s+sd}{        times (np.ndarray): The time points.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{with} \PYG{n}{h5py}\PYG{o}{.}\PYG{n}{File}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}r\PYGZdq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
        \PYG{n}{trajectories} \PYG{o}{=} \PYG{n}{f}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}trajectories\PYGZdq{}}\PYG{p}{][:]}
        \PYG{n}{time\PYGZus{}points} \PYG{o}{=} \PYG{n}{f}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}time\PYGZdq{}}\PYG{p}{][:]}
        \PYG{n}{prey} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[}\PYG{n}{system\PYGZus{}id}\PYG{p}{,} \PYG{p}{:}\PYG{n}{points}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}
        \PYG{n}{predator} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[}\PYG{n}{system\PYGZus{}id}\PYG{p}{,} \PYG{p}{:}\PYG{n}{points}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}
        \PYG{n}{times} \PYG{o}{=} \PYG{n}{time\PYGZus{}points}\PYG{p}{[:}\PYG{n}{points}\PYG{p}{]}

    \PYG{k}{return} \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{times}

\PYG{k}{def} \PYG{n+nf}{scaler}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Scales and rounds the prey and predator data.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        prey (np.ndarray): The prey values.}
\PYG{l+s+sd}{        predator (np.ndarray): The predator values.}
\PYG{l+s+sd}{        alpha (float): Scaling factor.}
\PYG{l+s+sd}{        decimals (int): Number of decimal places for rounding.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        rounded (np.ndarray): The scaled prey and predator values.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{prey} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{)}
    \PYG{n}{predator} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{predator}\PYG{p}{)}
    \PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{([}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{],} \PYG{n}{axis}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
    \PYG{n}{rescaled} \PYG{o}{=} \PYG{n}{data}\PYG{o}{/}\PYG{n}{alpha} \PYG{o}{*} \PYG{l+m+mi}{10}
    \PYG{n}{rounded} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{rescaled}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{n}{decimals}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{rounded}
\PYG{k}{def} \PYG{n+nf}{encoding}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Encode the prey and predator data into a string format. }

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        prey (np.ndarray): The prey values.}
\PYG{l+s+sd}{        predator (np.ndarray): The predator values.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        encoded (str): The encoded data string.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{series} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{((}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{))}
    \PYG{n}{encoded} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{([}\PYG{l+s+s1}{\PYGZsq{},\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n+nb}{map}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{,} \PYG{n}{row}\PYG{p}{))} \PYG{k}{for} \PYG{n}{row} \PYG{o+ow}{in} \PYG{n}{series}\PYG{p}{])}
    \PYG{k}{return} \PYG{n}{encoded}

\PYG{k}{def} \PYG{n+nf}{scale\PYGZus{}and\PYGZus{}encode}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{decimals}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Scale and encode the prey and predator data.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        prey (np.ndarray): The prey values.}
\PYG{l+s+sd}{        predator (np.ndarray): The predator values.}
\PYG{l+s+sd}{        alpha (float): Scaling factor.}
\PYG{l+s+sd}{        decimals (int): Number of decimal places for scaling.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        encoded (str): The encoded data string.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{prey} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{)}
    \PYG{n}{predator} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{predator}\PYG{p}{)}
    \PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{([}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{],} \PYG{n}{axis}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
    \PYG{n}{rescaled} \PYG{o}{=} \PYG{n}{data}\PYG{o}{/}\PYG{n}{alpha} \PYG{o}{*} \PYG{l+m+mi}{10}
    \PYG{n}{rescaled} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{rescaled}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{n}{decimals}\PYG{p}{)}
    \PYG{n}{series} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{((}\PYG{n}{rescaled}\PYG{p}{[:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{rescaled}\PYG{p}{[:,} \PYG{l+m+mi}{1}\PYG{p}{]))}
    \PYG{n}{encoded} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{([}\PYG{l+s+s1}{\PYGZsq{},\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n+nb}{map}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{,} \PYG{n}{row}\PYG{p}{))} \PYG{k}{for} \PYG{n}{row} \PYG{o+ow}{in} \PYG{n}{series}\PYG{p}{])}
    \PYG{k}{return} \PYG{n}{encoded}

\PYG{k}{def} \PYG{n+nf}{decoding}\PYG{p}{(}\PYG{n}{data}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Decode the encoded data back to prey and predator values, handling numeric extraction from strings.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        data (str): The encoded data string containing potential text labels.}
\PYG{l+s+sd}{        }
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        prey (np.ndarray): The decoded prey values.}
\PYG{l+s+sd}{        predator (np.ndarray): The decoded predator values.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{def} \PYG{n+nf}{extract\PYGZus{}number}\PYG{p}{(}\PYG{n}{s}\PYG{p}{):}
\PYG{+w}{        }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Extract first numeric value from string using regex.\PYGZdq{}\PYGZdq{}\PYGZdq{}}
        \PYG{n}{match} \PYG{o}{=} \PYG{n}{re}\PYG{o}{.}\PYG{n}{search}\PYG{p}{(}\PYG{l+s+sa}{r}\PYG{l+s+s2}{\PYGZdq{}[\PYGZhy{}+]?\PYGZbs{}d*\PYGZbs{}.?\PYGZbs{}d+\PYGZdq{}}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{())}
        \PYG{k}{if} \PYG{n}{match}\PYG{p}{:}
            \PYG{k}{return} \PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{match}\PYG{o}{.}\PYG{n}{group}\PYG{p}{())}
        \PYG{k}{return} \PYG{n+nb}{float}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{99}\PYG{p}{)}

    \PYG{n}{time\PYGZus{}steps} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{p}{)}
    
    \PYG{n}{decoded} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{([}
        \PYG{n+nb}{list}\PYG{p}{(}\PYG{n+nb}{map}\PYG{p}{(}\PYG{n}{extract\PYGZus{}number}\PYG{p}{,} \PYG{n}{step}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{},\PYGZsq{}}\PYG{p}{)))} 
        \PYG{k}{for} \PYG{n}{step} \PYG{o+ow}{in} \PYG{n}{time\PYGZus{}steps} 
        \PYG{k}{if} \PYG{n}{step}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{()}
        \PYG{o+ow}{and} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{step}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{},\PYGZsq{}}\PYG{p}{))} \PYG{o}{==} \PYG{l+m+mi}{2}
        \PYG{o+ow}{and} \PYG{n+nb}{all}\PYG{p}{(}\PYG{n}{value}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{()} \PYG{k}{for} \PYG{n}{value} \PYG{o+ow}{in} \PYG{n}{step}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{},\PYGZsq{}}\PYG{p}{))}
    \PYG{p}{][:}\PYG{l+m+mi}{100}\PYG{p}{])}
    
    \PYG{n}{prey} \PYG{o}{=} \PYG{n}{decoded}\PYG{p}{[:,} \PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{predator} \PYG{o}{=} \PYG{n}{decoded}\PYG{p}{[:,} \PYG{l+m+mi}{1}\PYG{p}{]}
    \PYG{k}{return} \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}

\PYG{k}{def} \PYG{n+nf}{get\PYGZus{}and\PYGZus{}process\PYGZus{}data}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{p}{,} \PYG{n}{system\PYGZus{}id}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{points}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Load and preprocess the dataset, including scaling and encoding.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use.}
\PYG{l+s+sd}{        system\PYGZus{}id (int): The ID of the system to load.}
\PYG{l+s+sd}{        points (int): The number of points to load.}
\PYG{l+s+sd}{        alpha (float): Scaling factor.}
\PYG{l+s+sd}{        decimals (int): Number of decimal places for scaling.}
\PYG{l+s+sd}{        }
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        tokenized\PYGZus{}data (dict): Tokenized data.}
\PYG{l+s+sd}{        encoded (str): Encoded data.}
\PYG{l+s+sd}{        combined\PYGZus{}data (np.ndarray): Data of original and scaled numerical values.}
\PYG{l+s+sd}{        times (np.ndarray): Time points.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{times} \PYG{o}{=} \PYG{n}{get\PYGZus{}dataset}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{n}{system\PYGZus{}id}\PYG{o}{=}\PYG{n}{system\PYGZus{}id}\PYG{p}{,} \PYG{n}{points}\PYG{o}{=}\PYG{n}{points}\PYG{p}{)}
    \PYG{n}{scaled} \PYG{o}{=} \PYG{n}{scaler}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{alpha} \PYG{o}{=} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{n}{decimals}\PYG{p}{)}
    \PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator} \PYG{o}{=} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{l+m+mi}{1}\PYG{p}{]} 
    \PYG{n}{encoded} \PYG{o}{=} \PYG{n}{encoding}\PYG{p}{(}\PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator}\PYG{p}{)}
    \PYG{n}{tokenized\PYGZus{}data} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{encoded}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}pt\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{tokenized\PYGZus{}data}\PYG{p}{,} \PYG{n}{encoded}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{((}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator}\PYG{p}{)),} \PYG{n}{times}

\PYG{k}{def} \PYG{n+nf}{load\PYGZus{}and\PYGZus{}preprocess}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{seed}\PYG{o}{=}\PYG{l+m+mi}{442}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Load and preprocess the dataset from an HDF5 file, applying scaling and encoding.}
\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        file\PYGZus{}path (str): Path to the HDF5 file.}
\PYG{l+s+sd}{        test\PYGZus{}size (float): Proportion of the dataset to include in the test split.}
\PYG{l+s+sd}{        alpha (float): Scaling factor.}
\PYG{l+s+sd}{        decimals (int): Number of decimal places for scaling.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        data (list): List containing train, validation, and test datasets.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{with} \PYG{n}{h5py}\PYG{o}{.}\PYG{n}{File}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}r\PYGZdq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
        \PYG{n}{trajectories} \PYG{o}{=} \PYG{n}{f}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}trajectories\PYGZdq{}}\PYG{p}{][:]}
        \PYG{n}{prey} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{]}
        \PYG{n}{predator} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{scaled} \PYG{o}{=} \PYG{n}{scaler}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{n}{decimals}\PYG{p}{)}
    \PYG{n}{new\PYGZus{}prey} \PYG{o}{=} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{new\PYGZus{}predator} \PYG{o}{=} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{stacked\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{((}\PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator}\PYG{p}{),} \PYG{n}{axis}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}

    \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{n}{seed}\PYG{p}{)}

    \PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{temp\PYGZus{}data} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{stacked\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{n}{test\PYGZus{}size}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
    \PYG{n}{val\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}data} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{temp\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

    \PYG{n}{data} \PYG{o}{=} \PYG{p}{[]}

    \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{p}{[}\PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{val\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}data}\PYG{p}{]:}
        \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator} \PYG{o}{=} \PYG{n}{d}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{d}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}
        \PYG{n}{encoded} \PYG{o}{=} \PYG{p}{[}\PYG{n}{encoding}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{)} \PYG{k}{for} \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{)]}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{encoded}\PYG{p}{)}

    \PYG{k}{return} \PYG{n}{data}

\PYG{k}{def} \PYG{n+nf}{load\PYGZus{}and\PYGZus{}process\PYGZus{}example}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{p}{,} \PYG{n}{points}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{seed}\PYG{o}{=}\PYG{l+m+mi}{442}\PYG{p}{,} \PYG{n+nb}{id}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Load and preprocess a specific example from the dataset, applying scaling and encoding.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        file\PYGZus{}path (str): Path to the HDF5 file.}
\PYG{l+s+sd}{        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use.}
\PYG{l+s+sd}{        points (int): The number of points to load.}
\PYG{l+s+sd}{        test\PYGZus{}size (float): Proportion of the dataset to include in the test split.}
\PYG{l+s+sd}{        alpha (float): Scaling factor.}
\PYG{l+s+sd}{        decimals (int): Number of decimal places for scaling.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        tokenized\PYGZus{}data (torch.Tensor): Tokenized data.}
\PYG{l+s+sd}{        encoded (str): Encoded data.}
\PYG{l+s+sd}{        combined\PYGZus{}data (np.ndarray): Data of original and scaled numerical values.}
\PYG{l+s+sd}{        time (np.ndarray): Time points.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{with} \PYG{n}{h5py}\PYG{o}{.}\PYG{n}{File}\PYG{p}{(}\PYG{n}{file\PYGZus{}path}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}r\PYGZdq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
        \PYG{n}{trajectories} \PYG{o}{=} \PYG{n}{f}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}trajectories\PYGZdq{}}\PYG{p}{][:]}
        \PYG{n}{prey} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{]}
        \PYG{n}{predator} \PYG{o}{=} \PYG{n}{trajectories}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}
        \PYG{n}{time} \PYG{o}{=} \PYG{n}{f}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}time\PYGZdq{}}\PYG{p}{][:]}

    \PYG{n}{scaled} \PYG{o}{=} \PYG{n}{scaler}\PYG{p}{(}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{n}{decimals}\PYG{p}{)}
    \PYG{n}{new\PYGZus{}prey} \PYG{o}{=} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{new\PYGZus{}predator} \PYG{o}{=} \PYG{n}{scaled}\PYG{p}{[:,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{stacked\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{((}\PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator}\PYG{p}{),} \PYG{n}{axis}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
    \PYG{n}{stacked} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{((}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{),} \PYG{n}{axis}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}

    \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{n}{seed}\PYG{p}{)}

    \PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{temp\PYGZus{}data} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{stacked\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{n}{test\PYGZus{}size}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
    \PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{test\PYGZus{}data} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{temp\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

    \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{n}{seed}\PYG{p}{)}

    \PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{temp} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{stacked}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{n}{test\PYGZus{}size}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
    \PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{test} \PYG{o}{=} \PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{temp}\PYG{p}{,} \PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

    \PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator} \PYG{o}{=} \PYG{n}{test}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{test}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}
    \PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator} \PYG{o}{=} \PYG{n}{test\PYGZus{}data}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{test\PYGZus{}data}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{encoded} \PYG{o}{=} \PYG{n}{encoding}\PYG{p}{(}\PYG{n}{test\PYGZus{}data}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{0}\PYG{p}{],} \PYG{n}{test\PYGZus{}data}\PYG{p}{[}\PYG{n+nb}{id}\PYG{p}{,} \PYG{p}{:,} \PYG{l+m+mi}{1}\PYG{p}{])}
    \PYG{n}{given\PYGZus{}text} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{([}\PYG{n}{chunk} \PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{encoded}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{p}{))} \PYG{k}{if} \PYG{n}{i} \PYG{o}{\PYGZlt{}} \PYG{n}{points}\PYG{p}{])}
    \PYG{n}{tokenized\PYGZus{}data} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{given\PYGZus{}text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}pt\PYGZdq{}}\PYG{p}{)}
    
    \PYG{k}{return} \PYG{n}{tokenized\PYGZus{}data}\PYG{p}{,} \PYG{n}{given\PYGZus{}text}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{column\PYGZus{}stack}\PYG{p}{((}\PYG{n}{prey}\PYG{p}{,} \PYG{n}{predator}\PYG{p}{,} \PYG{n}{new\PYGZus{}prey}\PYG{p}{,} \PYG{n}{new\PYGZus{}predator}\PYG{p}{)),} \PYG{n}{time}

\PYG{k}{def} \PYG{n+nf}{process\PYGZus{}data}\PYG{p}{(}\PYG{n}{texts}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{p}{,} \PYG{n}{points}\PYG{o}{=}\PYG{l+m+mi}{80}\PYG{p}{):}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Process the input texts by tokenizing and padding them.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        texts (list): List of input texts.}
\PYG{l+s+sd}{        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use.}
\PYG{l+s+sd}{        points (int): The number of points to load.}
\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        texts (np.ndarray): The processed texts.}
\PYG{l+s+sd}{        given\PYGZus{}input\PYGZus{}ids (torch.Tensor): The tokenized and padded input IDs.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{given\PYGZus{}input\PYGZus{}ids} \PYG{o}{=} \PYG{p}{[]}
    \PYG{k}{for} \PYG{n}{text} \PYG{o+ow}{in} \PYG{n}{texts}\PYG{p}{:}
        \PYG{n}{given\PYGZus{}text} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{([}\PYG{n}{chunk} \PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{};\PYGZsq{}}\PYG{p}{))} \PYG{k}{if} \PYG{n}{i} \PYG{o}{\PYGZlt{}} \PYG{n}{points}\PYG{p}{])}
        \PYG{n}{encoding\PYGZus{}given} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{given\PYGZus{}text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}pt\PYGZdq{}}\PYG{p}{,} \PYG{n}{padding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}max\PYGZus{}length\PYGZsq{}}\PYG{p}{,} \PYG{n}{padding\PYGZus{}side}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}left\PYGZsq{}}\PYG{p}{,} \PYG{n}{max\PYGZus{}length}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{)}
        \PYG{n}{given\PYGZus{}input\PYGZus{}ids}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{encoding\PYGZus{}given}\PYG{o}{.}\PYG{n}{input\PYGZus{}ids}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{])}
    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{([}\PYG{n}{text} \PYG{k}{for} \PYG{n}{text} \PYG{o+ow}{in} \PYG{n}{texts}\PYG{p}{]),} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{(}\PYG{n}{given\PYGZus{}input\PYGZus{}ids}\PYG{p}{)}
\end{Verbatim}
